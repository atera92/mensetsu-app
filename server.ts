/**
 * server.ts (5æ®µéšŽè©•ä¾¡ãƒ»ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆå¯¾å¿œ)
 */
import { WebSocketServer, WebSocket } from 'ws';
import dotenv from 'dotenv';
import { GoogleGenerativeAI } from "@google/generative-ai";
import { Buffer } from 'node:buffer';

dotenv.config({ path: '.env.local' });

const API_KEY = process.env.GEMINI_API_KEY;
if (!API_KEY) {
  console.error("âŒ ã‚¨ãƒ©ãƒ¼: APIã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“");
  process.exit(1);
}

const HOST = "generativelanguage.googleapis.com";
const PATH = "/ws/google.ai.generativelanguage.v1alpha.GenerativeService.BidiGenerateContent";
const GEMINI_URL = `wss://${HOST}${PATH}?key=${API_KEY}`;

// ãƒ¢ãƒ‡ãƒ«è¨­å®š
const TALK_MODEL = "models/gemini-2.5-flash-native-audio-preview-12-2025";
const JUDGE_MODEL = "gemini-2.0-flash-exp";

const genAI = new GoogleGenerativeAI(API_KEY);
const judgeModel = genAI.getGenerativeModel({ model: JUDGE_MODEL });

const wss = new WebSocketServer({ port: 8080 });

console.log(`ðŸ“ž é¢æŽ¥ã‚µãƒ¼ãƒãƒ¼(ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆå¯¾å¿œ)ãŒèµ·å‹•ã—ã¾ã—ãŸ`);

wss.on('connection', (clientWs: WebSocket) => {
  console.log("ðŸ‘¤ æŽ¥ç¶š");
  const geminiWs = new WebSocket(GEMINI_URL);
  let recordingBuffer: Buffer[] = [];

  const initialSetupMessage = {
    setup: {
      model: TALK_MODEL,
      generationConfig: { responseModalities: ["AUDIO"] }
    }
  };

  const systemPrompt = `
ã€é‡è¦è¨­å®šã€‘
è¨€èªž: æ—¥æœ¬èªž
å½¹å‰²: åŽ³æ ¼ãªæŽ¡ç”¨æ‹…å½“ã€Œä½è—¤ã€
ãƒ«ãƒ¼ãƒ«: 
- å¿…ãšæ—¥æœ¬èªžã§ã€è½ã¡ç€ã„ãŸãƒˆãƒ¼ãƒ³ã§è©±ã™ã“ã¨ã€‚
- å€™è£œè€…ã®ç™ºè¨€ã«å¯¾ã—ã¦ã¯ã€å¿…ãšã€Œãªã‚‹ã»ã©ã€ã€Œæ‰¿çŸ¥ã—ã¾ã—ãŸã€ãªã©ã®ç›¸æ§Œã‚’æ‰“ã£ã¦ã‹ã‚‰æ¬¡ã®è³ªå•ã«ç§»ã‚‹ã“ã¨ã€‚
`;

  geminiWs.on('open', () => {
    geminiWs.send(JSON.stringify(initialSetupMessage));
    geminiWs.send(JSON.stringify({
        clientContent: { turns: [{ role: "user", parts: [{ text: systemPrompt }] }], turnComplete: true }
    }));
  });

  geminiWs.on('message', (data: any) => {
    try {
        const msg = JSON.parse(data.toString());
        if (msg.serverContent?.modelTurn?.parts?.[0]?.inlineData) {
            const audioData = msg.serverContent.modelTurn.parts[0].inlineData.data;
            if (clientWs.readyState === WebSocket.OPEN) clientWs.send(data.toString());
            recordingBuffer.push(Buffer.from(audioData, 'base64'));
        }
    } catch(e) {}
  });

  clientWs.on('message', (data: any) => {
    try {
        const msg = JSON.parse(data.toString());

        if (msg.type === "FINISH_INTERVIEW") {
            console.log("ðŸ›‘ é¢æŽ¥çµ‚äº†ã€‚æŽ¡ç‚¹ã‚’é–‹å§‹ã—ã¾ã™...");
            generateScore(recordingBuffer).then(feedback => {
                if (feedback && clientWs.readyState === WebSocket.OPEN) {
                    clientWs.send(JSON.stringify({ type: "FEEDBACK_RESULT", data: feedback }));
                }
            });
            return;
        }

        if (msg.realtime_input?.media_chunks) {
            const audioData = msg.realtime_input.media_chunks[0].data;
            recordingBuffer.push(Buffer.from(audioData, 'base64'));
            if (geminiWs.readyState === WebSocket.OPEN) geminiWs.send(data);
        }
    } catch (e) {
        if (geminiWs.readyState === WebSocket.OPEN) geminiWs.send(data);
    }
  });

  // --- æŽ¡ç‚¹æ©Ÿèƒ½ (5æ®µéšŽè©•ä¾¡ã‚’è¿½åŠ ) ---
  async function generateScore(audioBuffer: Buffer[]) {
      try {
          if (audioBuffer.length === 0) return null;
          
          const fullAudio = Buffer.concat(audioBuffer);
          const wavBuffer = addWavHeader(fullAudio, 24000, 1, 16);
          const base64Audio = wavBuffer.toString('base64');

          // â˜…ã“ã“ã‚’å¤‰æ›´: 5ã¤ã®æŒ‡æ¨™ã‚’JSONã‚¹ã‚­ãƒ¼ãƒžã«è¿½åŠ 
          const prompt = `
ã‚ãªãŸã¯ãƒ™ãƒ†ãƒ©ãƒ³é¢æŽ¥å®˜ã§ã™ã€‚ä»¥ä¸‹ã®éŸ³å£°ã¯ã€Œæ¨¡æ“¬é¢æŽ¥ã®éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã€ã§ã™ã€‚
ã“ã®å€™è£œè€…ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ã‚’è©•ä¾¡ã—ã€ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
**å¿…ãšæ—¥æœ¬èªžã§å‡ºåŠ›ã™ã‚‹ã“ã¨ã€‚**

{
  "score": 0ã€œ100ã®æ•´æ•°,
  "metrics": {
    "voice_volume": 1ã€œ5ã®æ•´æ•° (å£°ã®å¤§ãã•),
    "response_quality": 1ã€œ5ã®æ•´æ•° (é©åˆ‡ãªå¿œç­”),
    "company_match": 1ã€œ5ã®æ•´æ•° (ä¼šç¤¾ã¨ã®ãƒžãƒƒãƒåº¦),
    "episodes": 1ã€œ5ã®æ•´æ•° (ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®å…·ä½“æ€§),
    "clarity": 1ã€œ5ã®æ•´æ•° (ã‚ã‹ã‚Šã‚„ã™ã•)
  },
  "good_points": "è©•ä¾¡ã§ãã‚‹ç‚¹ï¼ˆ1è¡Œï¼‰",
  "advice": "æ”¹å–„ã™ã¹ãç‚¹ï¼ˆè¾›å£ã§1è¡Œï¼‰",
  "comment": "ç·è©•ï¼ˆ1è¡Œï¼‰"
}
`;
          const result = await judgeModel.generateContent([
              { inlineData: { mimeType: "audio/wav", data: base64Audio } },
              { text: prompt }
          ]);

          const responseText = result.response.text();
          const jsonMatch = responseText.match(/\{[\s\S]*\}/);
          if (jsonMatch) {
              return JSON.parse(jsonMatch[0]);
          }
          return null;
      } catch (e) {
          console.error("æŽ¡ç‚¹ã‚¨ãƒ©ãƒ¼:", e);
          return null;
      }
  }

  geminiWs.on('close', () => clientWs.close());
  clientWs.on('close', () => geminiWs.close());
});

function addWavHeader(samples: Buffer, sampleRate: number, numChannels: number, bitDepth: number): Buffer {
    const byteRate = (sampleRate * numChannels * bitDepth) / 8;
    const blockAlign = (numChannels * bitDepth) / 8;
    const buffer = Buffer.alloc(44 + samples.length);
    buffer.write('RIFF', 0); buffer.writeUInt32LE(36 + samples.length, 4); buffer.write('WAVE', 8);
    buffer.write('fmt ', 12); buffer.writeUInt32LE(16, 16); buffer.writeUInt16LE(1, 20);
    buffer.writeUInt16LE(numChannels, 22); buffer.writeUInt32LE(sampleRate, 24);
    buffer.writeUInt32LE(byteRate, 28); buffer.writeUInt16LE(blockAlign, 32);
    buffer.writeUInt16LE(bitDepth, 34); buffer.write('data', 36);
    buffer.writeUInt32LE(samples.length, 40);
    samples.copy(buffer, 44);
    return buffer;
}