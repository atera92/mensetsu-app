import { NextResponse } from 'next/server';
import Groq from 'groq-sdk';
import OpenAI from 'openai';
import { createClient } from '@supabase/supabase-js';

export async function POST(req: Request) {
  console.log('ğŸš€ APIå‘¼ã³å‡ºã—é–‹å§‹ï¼');

  // 1. éµã®ãƒã‚§ãƒƒã‚¯
  const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;
  const supabaseKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY;

  if (!supabaseUrl || !supabaseKey) {
    console.error(
      'âŒ Supabaseã®éµãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼.env.localã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚'
    );
    return NextResponse.json({ error: 'Env vars missing' }, { status: 500 });
  } else {
    console.log('ğŸ”‘ éµã¯ã‚ã‚Šã¾ã—ãŸã€‚URL:', supabaseUrl);
  }

  // ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæº–å‚™
  const groq = new Groq({ apiKey: process.env.GROQ_API_KEY });
  const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
  const supabase = createClient(supabaseUrl, supabaseKey);

  try {
    const formData = await req.formData();
    const audioFile = formData.get('audio') as File;

    if (!audioFile) {
      console.error('âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå±Šã„ã¦ã„ã¾ã›ã‚“');
      return NextResponse.json({ error: 'No audio file' }, { status: 400 });
    }

    // --- ã€è€³ã€‘ ---
    console.log('ğŸ‘‚ éŸ³å£°èªè­˜ã‚¹ã‚¿ãƒ¼ãƒˆ...');
    const buffer = await audioFile.arrayBuffer();
    const transcription = await groq.audio.transcriptions.create({
      file: new File([buffer], 'input.wav', { type: 'audio/wav' }),
      model: 'whisper-large-v3',
      language: 'ja',
      response_format: 'json',
    });
    const userText = transcription.text;
    console.log('âœ… èªè­˜å®Œäº†:', userText);

    // --- ã€è„³ã€‘ ---
    console.log('ğŸ§  æ€è€ƒã‚¹ã‚¿ãƒ¼ãƒˆ...');
    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        {
          role: 'system',
          content: 'ã‚ãªãŸã¯å„ªã—ã„é¢æ¥å®˜ã§ã™ã€‚100æ–‡å­—ä»¥å†…ã§è¿”ç­”ã—ã¦ãã ã•ã„ã€‚',
        },
        { role: 'user', content: userText },
      ],
    });
    const aiText = completion.choices[0].message.content || 'ã‚¨ãƒ©ãƒ¼';
    console.log('âœ… æ€è€ƒå®Œäº†:', aiText);

    // --- ã€è¨˜æ†¶ã€‘ï¼ˆã“ã“ãŒå•é¡Œã®å ´æ‰€ï¼ï¼‰ ---
    console.log('ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ãƒˆãƒ©ã‚¤...');
    const dummyId = '00000000-0000-0000-0000-000000000000';

    // 1. ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ä¿å­˜ï¼ˆã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
    const { error: profileError } = await supabase
      .from('profiles')
      .upsert({ id: dummyId, plan_type: 'light' });

    if (profileError) {
      console.error('âŒ ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ä¿å­˜å¤±æ•—:', profileError); // â˜…ã“ã“ã«å‡ºã‚‹ã¯ãšï¼
    } else {
      console.log('âœ… ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ä¿å­˜OK');
    }

    // 2. ä¼šè©±ãƒ­ã‚°ä¿å­˜ï¼ˆã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
    const { data, error: interviewError } = await supabase
      .from('interviews')
      .insert({
        user_id: dummyId,
        transcript: userText,
        feedback: aiText,
        score: 80,
      })
      .select(); // selectã‚’ã¤ã‘ã‚‹ã¨ä¿å­˜ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã—ã¦ãã‚Œã¾ã™

    if (interviewError) {
      console.error('âŒ é¢æ¥ãƒ­ã‚°ä¿å­˜å¤±æ•—:', interviewError); // â˜…ã¾ãŸã¯ã“ã“ï¼
    } else {
      console.log('âœ… é¢æ¥ãƒ­ã‚°ä¿å­˜OKï¼ãƒ‡ãƒ¼ã‚¿:', data);
    }

// --- ã€å£ã€‘ ---
console.log("ğŸ‘„ éŸ³å£°åˆæˆã‚¹ã‚¿ãƒ¼ãƒˆ...");
const mp3Response = await openai.audio.speech.create({
  model: "tts-1",
  voice: "alloy",
  input: aiText,
});

// ã€ä¿®æ­£ç‚¹ã€‘Bufferã¨ã„ã†Node.jså°‚ç”¨ã®å½¢ã§ã¯ãªãã€ä¸–ç•Œæ¨™æº–ã®ArrayBufferã®ã¾ã¾æ¸¡ã—ã¾ã™
const audioData = await mp3Response.arrayBuffer();

return new NextResponse(audioData, {
  headers: { 
    'Content-Type': 'audio/mpeg', 
    'x-ai-text': encodeURIComponent(aiText) 
  },
});

} catch (error: any) {
console.error("ğŸ’¥ è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼:", error);
return NextResponse.json({ error: error.message }, { status: 500 });
}
}